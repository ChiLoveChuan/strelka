\documentclass{article}

\usepackage{natbib}

% for equation*
\usepackage{amsmath}

% for scalebox,...
\usepackage{graphics}

% hide hyperref links  with pdfborder (more portable than hidelinks option)
\usepackage[pdfborder={0 0 0}]{hyperref}

% for pseudocode
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\title{'Methods for Strelka Small Variant Caller'}


% simple scientific notation:
\newcommand{\e}[1]{\ensuremath{\times 10^{#1}}}

\begin{document}

\maketitle

\tableofcontents

\section{Overview}

On any release branch, the methods described here should reflect the default implementation in the source
repository containing this document.

\section{Methods}

\subsection{Workflow Overview}

Strelka comprises several workflows for small variant calling from mapped sequencing data. It includes workflows for analysis of germline variants from single-samples and multi-sample groups, somatic variants from matched tumor-normal sample pairs and denovo variants from parent-offspring trios.

The methods below describe several core components shared by all workflows in addition to workflow specific logic specialized for each type of variant calling problem. All workflows share a common sequence of analysis steps:

\begin{enumerate}
\item Preliminary estimation of parameters from sample data.
\item Division of the genome into segments to be analyzed in parallel
\item For each analyzed genome segment:
\begin{enumerate}
\item Filtration of input read alignments
\item Processing the input read alignments into a set of variant haplotype candidates.
\item Finding probability of variant haplotypes/haplotype combinations under various (germline, somatic, de-novo) models.
\item Empirical re-scoring of variants based on models trained from static truth sets.
\end{enumerate}
\item Joining parallel analysis results into final VCF(s)/reported output.
\end{enumerate}


\subsection{Preliminary Parameter Estimation}

Before entering the small  phase of the workflow, Strelka completes a rapid estimation of the sequencing depth for each chromosome. For somatic analysis this depth is only computed for the normal sample. This information is used downstream to filter out high-depth regions (details below) when Strelka is run in its default whole genome sequencing mode, these values can be ignored for exome or other targeted analyses.

\subsubsection{Chromosome depth estimation}

For each chromosome, depth is estimated using a modified median calculation. As a first step, each chromosome is partitioned into segments of similar size to ensure the estimation process samples several chromosome regions. The chromosome is divided into the smallest number of segments no larger than $S_{max}$, where all segments have nearly equal size (all sizes must be $S$ or $S+1$, given smallest segment size of $S$). If this procedure results in more than 20 segments then $S_max$ is doubled until 20 or fewer segments are found. $S_{max}$ is initialized to 2 Mbase.

The depth estimation procedure repeatedly cycles through all segments. Within each segment, at least 40,000 reads are scanned before moving to the next segment (additional reads are scanned until the mapping position changes.) After the target number of reads have been scanned from every segment in the chromosome, the procedure returns to the first position and repeats this procedure starting from the last unscanned position. The process repeats until the all reads in all segments are scanned or the depth estimate converges.

Each scanned read is filtered if it is unmapped. Otherwise the read alignment is ignored and the read is applied to a simple depth pileup assuming a complete and ungapped alignment starting from the mapping position. Every 1M reads triggers a convergence check, but only after every chromosome segment has been sampled at least once.

Depth is estimated from the resulting pileup, using a simple median over all depth observations from the pileup structure excluding zero counts. Convergence is checked between the depth estimate of the last convergence check and the current one. An absolute change of less than 0.05 is treated as converged (or given the median case, the integer median estimates must be an exact match).

The depth estimation procedure is run separately for each non-tumor sample, and all high-depth thresholds are set based on the sum of depth estimates over these samples.

\subsection{Small Variant Discovery}

\subsubsection{Read Filtration}

\subsubsection{Indel Candidacy}

Strelka uses indel candidacy as a preliminary filter to eliminate indel observations from consideration as variants if they are very likely to have been generated by error processes.  A candidate indel variant must minimally have 2 reads supporting it in at least one sample (this is relevant in multi-sample settings, such as somatic, trio de novo, and germline multi-sample calling).  If a candidate indel has more than 2 reads supporting it, Strelka evaluates its candidacy status using a one-sided binomial exact test, with the null hypothesis being that the indel coverage is generated by indel error processes.

Given a total locus coverage of $N$, indel coverage of $n_i$, and an indel error rate of $e_l$ (described below in "Indel Error Model"), we define the probability of some coverage $x$ being generated at the locus due to indel error as
\begin{equation*}
P(x | N, e_l) = \binom {N} {x} e^{x}_l (1 - e_l)^{N - x}
\end{equation*}
We can then define the probability of generating an indel with at least coverage $n_i$ due to indel error at a locus as follows:
\begin{equation*}
p_{error} = P(X >= n_i | N, e_l) = \sum_{x = n_i}^{N} P(x | N, e_l)
\end{equation*}

\noindent The indel is considered as a candidate variant if $p_{error} < p_{reject}$, where $p_{reject}$ is our rejection threshold for the null hypothesis.

\subsubsection{Read Realignment}

\subsection{Small Variant Scoring}

\subsubsection{Core Likelihood Function}

\paragraph{Indel Error Model}

Indel errors are approximated as a process which occurs independently in each read, with some fixed probably of an indel error occurring as a function of the local sequence STR context. Strelka's indel error parameters are currently set based on empirical observation of indel calling performance for both germline and somatic indel detection.

The default indel error rates used by strelka are a function of the local homopolymer context length only $l_{\text{STR}}$, so any expansion or contraction of a homopolymer sequence has an error rate indexed on the homopolymer length in the presumed source haplotype upon which the indel error process occurred. All other types of indels, including mutations of homopolymers which do not represent simple expansion/contraction events, and dinucleotide tract indels are have $l_{\text{STR}}$ set to one. By observation, the indel error rates are set to a log-linear ramp as a function of $l_{\text{STR}}$

\begin{equation*}
P(error | l_{\text{STR}}) = e_{l} \exp(f_{\text{STR}}(\log(e_{h})-\log(e_{l})))
\end{equation*}

\noindent ...where the constant indel errors set for low and high STR lengths are $e_{l} = 5\e{-5}$ and $e_{h} = 3\e{-4}$, and the fraction of high STR length is $f_{\text{STR}} = \max((l_{\text{STR}}-1),15)/15$.

As a special case, the germline indel genotyping model uses higher error rates to heuristically account for assembly and mapping errors. This is currently a scaling factor of 100, $P(error_{\text{germline}} | l_{\text{STR}}) = 100 * P(error | l_{\text{STR}})$


\subsubsection{Somatic Calling Model and Variant likelihoods}

The somatic calling model assumes that the samples are from diploid individuals. For both SNVs and indels, the normal genotype state space is the set of unphased diploid genotypes, $G_n = \{ \tt{ref}, \tt{het}, \tt{hom}\}$, where $\tt{ref}$, $\tt{het}$, and $\tt{hom}$ refer to the normal genotype being reference, heterozygous, and homozygous, respectively. The tumor genotype has two states $G_t = \{ \tt{nonsom}, \tt{som} \}$, where $\tt{nonsom}$ and $\tt{som}$ indicate the absence and presence of somatic mutation in the tumor sample, respectively. The method approximates a posterior probability on the joint tumor and normal genotypes.

\begin{align*}
	& P(G_t,G_n|D) \propto P(G_t,G_n) P(D|G_t,G_n) \\
\end{align*}


Here $D$ refers to the sequencing data from both samples. The likelihood term above is computed from independent sample-specific allele frequency likelihoods

\begin{align*}
	& P(D|G_t,G_n) = \int_{F_t,F_n}{P(D|F_t,F_n)P(F_t,F_n|G_t,G_n)} \\
	& = \int_{F_t,F_n}{P(D_t|F_t)P(D_n|F_n)P(F_t,F_n|G_t,G_n)},
\end{align*}

\noindent where $F_t$, $F_n$ refer to tumor and normal allele frequencies and $D_t$ and $D_n$ indicate tumor and normal sample data. In the above equation, the sample-specific allele frequency likelihoods $P(D_t|F_t)$ and $P(D_n|F_n)$ could in principle be supplied by any probabilistic variant caller. Strelka currently provides its own sample-specific frequency likelihoods (described in Section xxx). The genotype prior probability $P(G_t, G_n)$ and the joint allele-frequency distribution $P(F_t,F_n|G)$ are detailed below.

The posterior probability over tumor and normal genotypes $P(G_t,G_n|D)$ is used to compute the {\em somatic variant probability} (QSS for SNVs and QSI for indels).

\begin{equation*}
	P(G_t = {\tt som} | D) = \sum_{G_n \in \{ {\tt ref}, {\tt het}, \tt{hom} \}}{P(G_t={\tt som},G_n|D)}.
\end{equation*}

As previously discussed, this somatic variant probability is not ideal for detecting variants of interest because it does not distinguish somatic variant types. We therefore associate somatic calls with the probability of somatic variation {\em and} the normal sample genotype being $\tt ref$ (QSS\_NT for SNVs and QSI\_NT for indels), i.e., $P(G_t = {\tt som}, G_n = {\tt ref} | D)$. All Strelka quality scores discussed below express these values.

The Strelka workflow uses two calling tiers. All somatic calls are classified according to their most-likely normal genotype if that value is the same in tiers 1 and 2, and classified as conflicts otherwise.

\paragraph{Genomic prior}
Given the expected rate of single nucleotide differences between two unrelated haplotypes (Watterson theta) $\theta$, the normal genomic prior $P(G_n)$ over the set of diploid genotypes is

\begin{equation*}
P(G_n)=
\begin{cases}
	\theta & \text{if } G_n = {\tt het} \\
	\theta/2 & \text{if } G_n = {\tt hom} \\
	1 - 3\theta/2 & \text{if } G_n = {\tt ref} \\
\end{cases}
\end{equation*}

\noindent where $\theta_{\text{SNV}}=1\e{-3}$ for SNVs and $\theta_{\text{indel}}=1\e{-4}$ for indels. Given the somatic state prior $P(G_t={\tt som}) = \gamma$, the genomic prior is

\begin{equation*}
P(G_t, G_n)=
\begin{cases}
	(1 - \gamma) P(G_n) & \text{if } G_t = {\tt nonsom} \\
	\gamma P(G_n) & \text{if } G_t = {\tt som}. \\
\end{cases}
\end{equation*}

\noindent where $\gamma$ is set to $\gamma_{\text{SNV}} = 1\e{-3}$ and $\gamma_{\text{indel}} = 1\e{-6}$ for SNVs and indels. Note that $\gamma$ is expected to scale the somatic variant probabilities but not substantially influence their rank, thus its value was chosen empirically to provide reasonable variant probabilities and are not adjusted for different samples in practice.


\paragraph{Joint allele-frequency prior}
The prior probability on the tumor and normal allele-frequencies $P(F_t, F_n|G_t, G_n)$ encodes the concept that the normal sample is a mixture of diploid germline variation and noise while the tumor sample is a mixture of the normal sample and somatic variation. Let ${\cal C} (F_n, G_n) = 1$ if $F_n$ is a {\em canonical} diploid allele frequency of $G_n$ and ${\cal C} (F_n, G_n) = 0$ otherwise. For example, ${\cal C} (F_n=0, G_n = {\tt ref}) = 1$ and ${\cal C} (F_n=0.4, G_n = {\tt ref}) = 0$. The joint frequency prior is defined as follows.

% Non-somatic
\begin{equation*}
P(F_t, F_n | G_t = {\tt nonsom}, G_n)=
\begin{cases}
	0 & \text{ if } F_t \neq F_n \\
	1-\mu & \text{ if } F_t = F_n \text{ and }{\cal C}(F_n, G_n) = 1 \\
	\mu U(F_t) & \text{ if } F_t = F_n \text{ and }{\cal C}(F_n, G_n) = 0 \\
\end{cases}
\end{equation*}

% Somatic, normal genotype ref
\begin{equation*}
P(F_t, F_n | G_t = {\tt som}, G_n = {\tt ref})=
\begin{cases}
	(1-\mu)U(F_t) & \text{ if } F_t \neq F_n \text{ and } F_n \leq \tau F_t \\
	0 & \text{ otherwise } \\
\end{cases}
\end{equation*}

% Somatic, normal genotype het or hom
\begin{equation*}
P(F_t, F_n | G_t = {\tt som}, G_n \neq {\tt ref})=
\begin{cases}
	(1-\mu)U(F_t) & \text{ if } F_t \neq F_n \text{ and } {\cal C}(F_n, G_n) = 1\\
	0 & \text{ otherwise } \\
\end{cases}
\end{equation*}

\noindent Here, $\tau$ represents the {\em contamination tolerance}, $U(F_t)$ refers to a uniform distribution over the allowed tumor allele frequencies and $\mu$ indicates the noise term. The contamination tolerance term is introduced to allow for contamination in the normal sample by some fraction of tumor cells. This is particularly useful for analyses of liquid tumors, where normal sample is almost always contaminated by tumor cells. The contamination tolerance is set to $0.15$. The noise term abstracts various sequencing, read mapping and assembly issues which could produce an unexpected allele frequency shared in the tumor and normal samples. For SNVs, the noise contribution is set to $\mu_{\text{SNV}} = 5 \times 10^{-10}$. For indels, it is dynamically estimated as described in Section xxx.

% The description of the strand-bias model is not included here because it is not used in the quality score calculation.

\paragraph{Practical computation}
The continuous allele frequencies modeled above are efficiently computed by dividing each allele-pair axis into a set of equidistant points and performing the somatic probability computation over the resulting discrete point set. Several point resolutions were attempted to confirm the expected stability and convergence of results as resolution increased. A resolution of 21 points per axis is used for all computations by default. We expect that this resolution should be increased for improved detection of somatic allele frequencies lower than 5\%.

\subsubsection{Somatic Filtration and Scoring}

\subsubsection{Germline Calling Model and Genotype likelihoods}

\subsubsection{Germline Filtration and Scoring}

\subsubsection{Denovo Calling Model and Genotype likelihoods}

\subsubsection{Denovo Filtration and Scoring}


\bibliographystyle{alpha}
\bibliography{methods}

\end{document}
